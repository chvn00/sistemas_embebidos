# -*- coding: utf-8 -*-
"""MLP_proy_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SyE9ySj0w9ZJH-Gjx-Lp1WEOUbVaduUv
"""

import numpy as np
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

np.random.seed(42)

# ============================================
# 2. Generador de datos sintéticos
#    Simula una mini línea de producción
# ============================================

def generar_muestra():
    """
    Genera una sola muestra sintética del proceso.

    Variables "físicas":
      - distancia (cm):  5 a 20 aprox.
      - luz (0-1):       intensidad/reflectancia
      - temperatura (°C): 20 a 90 aprox.
      - modo (0,1,2,3):  tipo de producto / modo de operación

    Retorna:
      x_norm: vector de 4 features normalizadas en [0,1]
      y: clase (0 = NORMAL, 1 = ADVERTENCIA, 2 = CRÍTICO)
    """

    rng = np.random.default_rng()

    # --- 1) Elegimos modo de operación (0..3) ---
    modo = rng.integers(0, 4)  # 0,1,2,3

    # --- 2) Definimos un "estado base" casi ideal ---
    # Ideal: pieza bien posicionada, iluminación correcta, temperatura razonable
    dist = rng.normal(10, 1.0)     # ideal ~10 cm
    luz  = rng.normal(0.6, 0.1)    # ideal ~0.6 (0-1)
    temp = rng.normal(50, 5.0)     # ideal ~50 °C

    # --- 3) A veces introducimos defectos / desviaciones ---
    # Probabilidad de que haya "problemas" en alguna variable
    if rng.random() < 0.5:
        # Escogemos una o dos variables para deformar
        n_vars_defect = rng.integers(1, 3)
        vars_defect = rng.choice(['dist', 'luz', 'temp'], size=n_vars_defect, replace=False)

        for v in vars_defect:
            if v == 'dist':
                # pieza demasiado cerca o demasiado lejos
                if rng.random() < 0.5:
                    dist = rng.uniform(4, 6)   # demasiado cerca
                else:
                    dist = rng.uniform(16, 20) # demasiado lejos
            elif v == 'luz':
                # pieza muy oscura o muy clara
                if rng.random() < 0.5:
                    luz = rng.uniform(0.0, 0.25)
                else:
                    luz = rng.uniform(0.8, 1.0)
            elif v == 'temp':
                # horno / motor muy frío o sobrecalentado
                if rng.random() < 0.5:
                    temp = rng.uniform(20, 35)
                else:
                    temp = rng.uniform(70, 90)

    # --- 4) Recortamos a rangos razonables ---
    dist = float(np.clip(dist, 4, 20))
    luz  = float(np.clip(luz, 0.0, 1.0))
    temp = float(np.clip(temp, 20, 90))

    # --- 5) Definimos una regla "industrial" para la clase destino (etiqueta) ---
    # Calculamos penalizaciones por desviaciones
    penalty = 0

    # Distancia: ideal 8-12, aceptable 7-14
    if dist < 7 or dist > 14:
        penalty += 1
    if dist < 6 or dist > 16:
        penalty += 1  # penalización adicional si está muy mal

    # Luz: ideal 0.4-0.7, aceptable 0.3-0.8
    if luz < 0.3 or luz > 0.8:
        penalty += 1
    if luz < 0.2 or luz > 0.9:
        penalty += 1

    # Temperatura: ideal 45-55, aceptable 40-65
    if temp < 40 or temp > 65:
        penalty += 1
    if temp < 35 or temp > 75:
        penalty += 1

    # El modo puede hacer más estricta la inspección para algunos productos
    # Por ejemplo, modo 3 es un producto "premium" con control más estricto
    if modo == 3 and (temp < 45 or temp > 60):
        penalty += 1

    # Asignamos clase según penalización total
    # 0 = NORMAL, 1 = ADVERTENCIA, 2 = CRÍTICO
    if penalty <= 1:
        y = 0
    elif penalty == 2:
        y = 1
    else:
        y = 2

    # --- 6) Normalización de las entradas para el MLP (muy importante para replicar en la Pi) ---
    # Definimos normalizaciones simples, entre 0 y 1:
    # Nota: estas fórmulas se deben usar también en la Raspberry Pi.
    dist_norm = (dist - 4.0) / (20.0 - 4.0)       # 4..20 -> 0..1
    temp_norm = (temp - 20.0) / (90.0 - 20.0)     # 20..90 -> 0..1
    luz_norm  = luz                                # ya está en 0..1
    modo_norm = modo / 3.0                        # 0..3 -> 0..1

    x_norm = np.array([dist_norm, luz_norm, temp_norm, modo_norm], dtype=np.float32)

    return x_norm, y


def generar_dataset(N=2000):
    """
    Genera N muestras (X, y) usando la función anterior.
    X: matriz (N, 4)
    y: vector (N,)
    """
    X_list, y_list = [], []
    for _ in range(N):
        x, label = generar_muestra()
        X_list.append(x)
        y_list.append(label)
    X = np.vstack(X_list)
    y = np.array(y_list, dtype=int)
    return X, y


# ============================================
# 3. Crear dataset y explorar distribución
# ============================================

X, y = generar_dataset(N=3000)
print("Dimensiones de X:", X.shape)   # (N, 4)
print("Dimensiones de y:", y.shape)   # (N,)

unique, counts = np.unique(y, return_counts=True)
print("Distribución de clases (0=Normal, 1=Advertencia, 2=Crítico):")
for cls, cnt in zip(unique, counts):
    print(f"  Clase {cls}: {cnt} muestras ({cnt/len(y)*100:.1f}%)")

# ============================================
# 4. Separar en entrenamiento y prueba
# ============================================
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.25, random_state=0, stratify=y
)

print("Train:", X_train.shape, " Test:", X_test.shape)

# ============================================
# 5. Definir y entrenar la MLP
#    Arquitectura ejemplo: 4 -> 8 -> 3
# ============================================

mlp = MLPClassifier(
    hidden_layer_sizes=(8,),    # una capa oculta de 8 neuronas
    activation='relu',
    solver='adam',
    max_iter=2000,
    random_state=0
)

mlp.fit(X_train, y_train)

# ============================================
# 6. Evaluación
# ============================================
y_pred = mlp.predict(X_test)

print("\nAccuracy en prueba:", accuracy_score(y_test, y_pred))
print("\nReporte de clasificación:")
print(classification_report(y_test, y_pred, digits=3))

print("Matriz de confusión:")
print(confusion_matrix(y_test, y_pred))

# ============================================
# 7. Extraer pesos del MLP para la Raspberry Pi
#    coefs_[0]: (n_features, n_hidden)
#    coefs_[1]: (n_hidden, n_outputs)
# ============================================

W1 = mlp.coefs_[0]       # (4, 8)
b1 = mlp.intercepts_[0]  # (8,)
W2 = mlp.coefs_[1]       # (8, 3)
b2 = mlp.intercepts_[1]  # (3,)

# np.set_printoptions(precision=5, suppress=True) # This removes commas

# Custom formatter for floats to ensure 5 decimal places and no suppression
float_formatter = lambda x: "%.5f" % x

print("\n=== Pesos para implementar en la Raspberry Pi ===")
print("W1.shape:", W1.shape)
print("W1 = np.array(")
print(np.array2string(W1, separator=', ', formatter={'float_kind':float_formatter}))
print(")")
print("\nb1.shape:", b1.shape)
print("b1 = np.array(")
print(np.array2string(b1, separator=', ', formatter={'float_kind':float_formatter}))
print(")")

print("\nW2.shape:", W2.shape)
print("W2 = np.array(")
print(np.array2string(W2, separator=', ', formatter={'float_kind':float_formatter}))
print(")")
print("\nb2.shape:", b2.shape)
print("b2 = np.array(")
print(np.array2string(b2, separator=', ', formatter={'float_kind':float_formatter}))
print(")")