{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhO83VHt3LO3+8epnfdIa0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chvn00/sistemas_embebidos/blob/main/MLP_proy_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proyecto Final - Parte MLP\n",
        "# Profesor: Cesar Hernando Valencia Niño\n",
        "# Sistemas Embebidos\n",
        "\n",
        "## Entrenamiento del Modelo de IA para la Línea de Producción Inteligente\n",
        "Generación del dataset sintético y entrenamiento de una red neuronal MLP embebible en Raspberry Pi\n",
        "\n",
        "En este cuaderno se desarrolla el proceso completo de construcción, entrenamiento y extracción de pesos de una red neuronal del tipo MLP (Multilayer Perceptron) que luego será implementada directamente en una Raspberry Pi como parte de una mini línea de producción inteligente. Este modelo será el encargado de tomar decisiones automáticas basadas en varias lecturas de sensores.\n",
        "\n",
        "## Arquitectura del modelo neuronal\n",
        "\n",
        "La red que entrenaremos tiene una arquitectura 4 → 32 → 3, estructurada de la siguiente manera:\n",
        "\n",
        "4 neuronas de entrada:\n",
        "Representan las cuatro variables del proceso industrial simulado:\n",
        "\n",
        "- Distancia (posición de la pieza).\n",
        "\n",
        "- Luz (reflectancia/color) para estimar si la pieza está dentro de una tolerancia visual.\n",
        "\n",
        "- Temperatura, simulando un horno o motor industrial.\n",
        "\n",
        "- Modo de operación, codificado a partir de un DIP switch (tipo de producto o nivel de exigencia).\n",
        "\n",
        "1 capa oculta con 8 neuronas y función de activación ReLU, que le da capacidad no lineal para separar regiones complejas del espacio de entrada.\n",
        "\n",
        "3 neuronas de salida, correspondientes a las tres decisiones del sistema:\n",
        "\n",
        "- Clase 0: Producto Aceptado (estado normal)\n",
        "\n",
        "- Clase 1: Producto en Revisión (advertencia)\n",
        "\n",
        "- Clase 2: Producto Rechazado / Condición crítica\n",
        "\n",
        "Este modelo es suficientemente simple para correr en tiempo real dentro de la Raspberry Pi, pero lo bastante flexible para tomar decisiones útiles basadas en múltiples condiciones simultáneas.\n",
        "\n",
        "## Dataset sintético: simulación del proceso industrial\n",
        "\n",
        "Como no disponemos de datos reales de una fábrica, se genera un dataset sintético realista, donde cada muestra representa una \"pieza\" pasando por una estación de inspección. Para cada pieza se simulan:\n",
        "\n",
        "- Distancia: si la pieza está bien posicionada (8–12 cm) o demasiado cerca/lejos (fallo).\n",
        "\n",
        "- Luz: si la superficie refleja el nivel esperado (prueba visual).\n",
        "\n",
        "- Temperatura: si el proceso térmico estuvo dentro del rango normal o presenta enfriamiento/sobrecalentamiento.\n",
        "\n",
        "- Modo: define tolerancias más o menos estrictas según el tipo de producto.\n",
        "\n",
        "Con estas variables se define una regla lógica industrial que clasifica cada pieza como normal, advertencia o crítica según sus desviaciones. Esta regla es desconocida para la red neuronal, pero se usa para generar las etiquetas del dataset. Luego el modelo aprenderá a aproximar este comportamiento.\n",
        "\n",
        "El dataset final contiene miles de muestras distribuidas entre los tres estados posibles, lo que permite un entrenamiento estable y generalizable.\n",
        "\n",
        "## Objetivo del entrenamiento\n",
        "\n",
        "El objetivo es entrenar un modelo capaz de:\n",
        "\n",
        "- Recibir valores normalizados de distancia, luz, temperatura y modo.\n",
        "\n",
        "- Procesarlos mediante el MLP para obtener una predicción.\n",
        "\n",
        "- Clasificar cada pieza en NORMAL, ADVERTENCIA o CRÍTICO.\n",
        "\n",
        "- Poder exportarse a la Raspberry Pi, donde el modelo será ejecutado sin scikit-learn mediante únicamente operaciones matriciales (multiplicaciones y sumas).\n",
        "\n",
        "## Qué se obtiene al finalizar este Colab\n",
        "\n",
        "Al final del cuaderno tendrás:\n",
        "\n",
        "- Un dataset sintético realista que representa condiciones industriales.\n",
        "\n",
        "- Una red neuronal entrenada para clasificar piezas en una mini línea de producción.\n",
        "\n",
        "  - Las matrices de pesos:\n",
        "\n",
        "  - W1, b1 para la capa oculta.\n",
        "\n",
        "  - W2, b2 para la capa de salida.\n",
        "\n",
        "- Estas matrices estarán impresas en pantalla para copiarse al código embebido de la Raspberry Pi.\n",
        "\n",
        "- Un modelo listo para usarse en inferencia en tiempo real, controlando LEDs, alertas y acciones del sistema físico."
      ],
      "metadata": {
        "id": "vRE-re0vElvF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcJCUPlgCbXE",
        "outputId": "de13f04f-34f4-4a0b-b559-0d3c2463d1d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones de X: (3000, 4)\n",
            "Dimensiones de y: (3000,)\n",
            "\n",
            "Primeras 5 filas de X:\n",
            " [[0.4411  0.5004  0.13894 0.33333]\n",
            " [0.34287 0.50525 0.06516 0.66667]\n",
            " [0.36516 0.70789 0.39292 0.     ]\n",
            " [0.2725  0.53403 0.3314  0.33333]\n",
            " [0.37947 0.55869 0.43881 0.66667]]\n",
            "\n",
            "Primeras 5 etiquetas de y:\n",
            " [1 1 0 0 0]\n",
            "Distribución de clases (0=Normal, 1=Advertencia, 2=Crítico):\n",
            "  Clase 0: 1000 muestras (33.3%)\n",
            "  Clase 1: 1000 muestras (33.3%)\n",
            "  Clase 2: 1000 muestras (33.3%)\n",
            "Train: (2250, 4)  Test: (750, 4)\n",
            "\n",
            "Accuracy en prueba: 0.9453333333333334\n",
            "\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0      0.992     0.964     0.978       250\n",
            "           1      0.916     0.920     0.918       250\n",
            "           2      0.930     0.952     0.941       250\n",
            "\n",
            "    accuracy                          0.945       750\n",
            "   macro avg      0.946     0.945     0.946       750\n",
            "weighted avg      0.946     0.945     0.946       750\n",
            "\n",
            "Matriz de confusión:\n",
            "[[241   9   0]\n",
            " [  2 230  18]\n",
            " [  0  12 238]]\n",
            "\n",
            "=== Pesos para implementar en la Raspberry Pi ===\n",
            "W1.shape: (4, 32)\n",
            "W1 = np.array(\n",
            "[[-0.00868, -0.00000, 0.29000, 0.00000, -0.03079, 2.94352, 0.52924,\n",
            "  0.34942, 0.36757, -0.37003, 0.48471, 0.00000, -0.21169, 2.95285,\n",
            "  0.00000, -1.70130, -4.43235, 1.92322, 1.92413, 0.38040, 0.12227,\n",
            "  1.13705, -1.82776, 0.42883, -0.00000, 2.11591, -3.09006, 0.06307,\n",
            "  0.12168, 0.18460, -0.00000, -0.00000],\n",
            " [0.77617, 0.00000, -3.25014, 0.00000, 0.98972, 0.35068, 0.28092,\n",
            "  -0.33426, -0.54850, -0.56965, -0.24030, 0.00000, -0.39825, 0.60684,\n",
            "  -0.00000, -1.11034, 0.59857, -1.97512, 1.87368, -1.99197, -0.14228,\n",
            "  -0.72943, 0.90514, -0.64421, -0.00000, -2.40594, 1.78046, -0.83433,\n",
            "  0.15352, -3.58983, -0.00000, 0.00000],\n",
            " [-3.56731, 0.00000, 0.82798, 0.00000, 2.86101, -0.35648, 0.55326,\n",
            "  0.05028, 0.45955, 0.10000, 0.28227, -0.00000, -0.11855, 0.19260,\n",
            "  -0.00000, -1.78407, -0.09156, -2.25949, -2.43606, 0.11120, 0.06259,\n",
            "  -0.54191, 2.03306, -0.16470, -0.00000, 2.22714, 0.22243, 0.13318,\n",
            "  -4.06540, 0.07969, 0.00000, 0.00000],\n",
            " [0.11017, -0.00000, -0.19741, 0.00000, 0.01381, -0.67836, 0.56108,\n",
            "  0.48834, -0.00072, -0.04448, 0.37179, -0.00000, -0.30264, 0.34821,\n",
            "  0.00000, 0.19292, -0.72704, 0.03333, -0.01932, -0.74990, 0.18740,\n",
            "  0.00907, 0.05580, 0.44855, -0.00000, 0.16675, 0.70663, -0.10569,\n",
            "  0.30936, 1.00759, -0.00000, 0.00000]]\n",
            ")\n",
            "\n",
            "b1.shape: (32,)\n",
            "b1 = np.array(\n",
            "[1.20876, -0.18717, 1.56434, -0.07541, -1.76165, -0.83888, 1.23363,\n",
            " 1.68836, 1.71510, 1.45761, 1.77194, -0.05600, 1.73195, -1.43456, -0.05237,\n",
            " 2.05010, 1.20074, 1.32995, -0.73517, 1.12407, 1.40494, 0.57149, -0.66326,\n",
            " 1.96846, -0.29529, -0.66222, -0.03027, 1.33456, 1.35971, 1.64351,\n",
            " -0.07578, -0.35177]\n",
            ")\n",
            "\n",
            "W2.shape: (32, 3)\n",
            "W2 = np.array(\n",
            "[[-3.26287, -2.07233, 4.33140],\n",
            " [-0.00000, 0.00000, 0.00000],\n",
            " [-4.16899, -1.45010, 4.09748],\n",
            " [0.00000, 0.00000, -0.00000],\n",
            " [-6.42248, -1.88242, 5.58736],\n",
            " [-4.12514, -1.20877, 4.04131],\n",
            " [0.82897, -0.47166, -0.61388],\n",
            " [1.09665, 0.06749, -0.83459],\n",
            " [1.41469, 0.32941, -0.77716],\n",
            " [1.67224, 0.81106, -1.81994],\n",
            " [0.86072, -0.19018, -0.88101],\n",
            " [0.00000, 0.00000, -0.00000],\n",
            " [1.27831, 0.36906, -1.89933],\n",
            " [-4.69107, -2.49054, 4.41040],\n",
            " [-0.00000, 0.00000, -0.00000],\n",
            " [-6.67530, 3.30050, 0.69605],\n",
            " [-6.72663, -0.58941, 4.65204],\n",
            " [-4.92553, 4.44828, -2.14923],\n",
            " [-5.76059, 3.58682, -0.41765],\n",
            " [-1.13328, -2.56113, 3.40196],\n",
            " [0.97988, 0.34192, -0.76232],\n",
            " [2.55976, -1.40867, 0.72127],\n",
            " [-5.28134, 1.95505, 2.08960],\n",
            " [1.59395, 0.00190, -1.29178],\n",
            " [-0.00000, 0.00000, -0.00000],\n",
            " [-4.32629, 4.32743, -1.76007],\n",
            " [-4.79923, -0.42367, 3.88758],\n",
            " [1.27663, 0.46734, -1.64721],\n",
            " [-5.65057, -2.11962, 4.58235],\n",
            " [-3.60459, -2.66408, 4.85299],\n",
            " [0.00000, 0.00000, 0.00000],\n",
            " [-0.00000, -0.00000, 0.00000]]\n",
            ")\n",
            "\n",
            "b2.shape: (3,)\n",
            "b2 = np.array(\n",
            "[1.15505, 0.37733, -0.65905]\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# ============================================\n",
        "# 2. Generador de datos sintéticos\n",
        "#    Simula una mini línea de producción\n",
        "# ============================================\n",
        "\n",
        "def generar_muestra():\n",
        "    \"\"\"\n",
        "    Genera una sola muestra sintética del proceso.\n",
        "\n",
        "    Variables \"físicas\":\n",
        "      - distancia (cm):  5 a 20 aprox.\n",
        "      - luz (0-1):       intensidad/reflectancia\n",
        "      - temperatura (°C): 20 a 90 aprox.\n",
        "      - modo (0,1,2,3):  tipo de producto / modo de operación\n",
        "\n",
        "    Retorna:\n",
        "      x_norm: vector de 4 features normalizadas en [0,1]\n",
        "      y: clase (0 = NORMAL, 1 = ADVERTENCIA, 2 = CRÍTICO)\n",
        "    \"\"\"\n",
        "\n",
        "    rng = np.random.default_rng()\n",
        "\n",
        "    # --- 1) Elegimos modo de operación (0..3) ---\n",
        "    modo = rng.integers(0, 4)  # 0,1,2,3\n",
        "\n",
        "    # --- 2) Definimos un \"estado base\" casi ideal ---\n",
        "    # Ideal: pieza bien posicionada, iluminación correcta, temperatura razonable\n",
        "    dist = rng.normal(10, 1.0)     # ideal ~10 cm\n",
        "    luz  = rng.normal(0.6, 0.1)    # ideal ~0.6 (0-1)\n",
        "    temp = rng.normal(50, 5.0)     # ideal ~50 °C\n",
        "\n",
        "    # --- 3) A veces introducimos defectos / desviaciones ---\n",
        "    # Probabilidad de que haya \"problemas\" en alguna variable\n",
        "    if rng.random() < 0.5:\n",
        "        # Escogemos una o dos variables para deformar\n",
        "        n_vars_defect = rng.integers(1, 3)\n",
        "        vars_defect = rng.choice(['dist', 'luz', 'temp'], size=n_vars_defect, replace=False)\n",
        "\n",
        "        for v in vars_defect:\n",
        "            if v == 'dist':\n",
        "                # pieza demasiado cerca o demasiado lejos\n",
        "                if rng.random() < 0.5:\n",
        "                    dist = rng.uniform(4, 6)   # demasiado cerca\n",
        "                else:\n",
        "                    dist = rng.uniform(16, 20) # demasiado lejos\n",
        "            elif v == 'luz':\n",
        "                # pieza muy oscura o muy clara\n",
        "                if rng.random() < 0.5:\n",
        "                    luz = rng.uniform(0.0, 0.25)\n",
        "                else:\n",
        "                    luz = rng.uniform(0.8, 1.0)\n",
        "            elif v == 'temp':\n",
        "                # horno / motor muy frío o sobrecalentado\n",
        "                if rng.random() < 0.5:\n",
        "                    temp = rng.uniform(20, 35)\n",
        "                else:\n",
        "                    temp = rng.uniform(70, 90)\n",
        "\n",
        "    # --- 4) Recortamos a rangos razonables ---\n",
        "    dist = float(np.clip(dist, 4, 20))\n",
        "    luz  = float(np.clip(luz, 0.0, 1.0))\n",
        "    temp = float(np.clip(temp, 20, 90))\n",
        "\n",
        "    # --- 5) Definimos una regla \"industrial\" para la clase destino (etiqueta) ---\n",
        "    # Calculamos penalizaciones por desviaciones\n",
        "    penalty = 0\n",
        "\n",
        "    # Distancia: ideal 8-12, aceptable 7-14\n",
        "    if dist < 7 or dist > 14:\n",
        "        penalty += 1\n",
        "    if dist < 6 or dist > 16:\n",
        "        penalty += 1  # penalización adicional si está muy mal\n",
        "\n",
        "    # Luz: ideal 0.4-0.7, aceptable 0.3-0.8\n",
        "    if luz < 0.3 or luz > 0.8:\n",
        "        penalty += 1\n",
        "    if luz < 0.2 or luz > 0.9:\n",
        "        penalty += 1\n",
        "\n",
        "    # Temperatura: ideal 45-55, aceptable 40-65\n",
        "    if temp < 40 or temp > 65:\n",
        "        penalty += 1\n",
        "    if temp < 35 or temp > 75:\n",
        "        penalty += 1\n",
        "\n",
        "    # El modo puede hacer más estricta la inspección para algunos productos\n",
        "    # Por ejemplo, modo 3 es un producto \"premium\" con control más estricto\n",
        "    if modo == 3 and (temp < 45 or temp > 60):\n",
        "        penalty += 1\n",
        "\n",
        "    # Asignamos clase según penalización total\n",
        "    # 0 = NORMAL, 1 = ADVERTENCIA, 2 = CRÍTICO\n",
        "    if penalty <= 1:\n",
        "        y = 0\n",
        "    elif penalty == 2:\n",
        "        y = 1\n",
        "    else:\n",
        "        y = 2\n",
        "\n",
        "    # --- 6) Normalización de las entradas para el MLP (muy importante para replicar en la Pi) ---\n",
        "    # Definimos normalizaciones simples, entre 0 y 1:\n",
        "    # Nota: estas fórmulas se deben usar también en la Raspberry Pi.\n",
        "    dist_norm = (dist - 4.0) / (20.0 - 4.0)       # 4..20 -> 0..1\n",
        "    temp_norm = (temp - 20.0) / (90.0 - 20.0)     # 20..90 -> 0..1\n",
        "    luz_norm  = luz                                # ya está en 0..1\n",
        "    modo_norm = modo / 3.0                        # 0..3 -> 0..1\n",
        "\n",
        "    x_norm = np.array([dist_norm, luz_norm, temp_norm, modo_norm], dtype=np.float32)\n",
        "\n",
        "    return x_norm, y\n",
        "\n",
        "\n",
        "def generar_dataset(samples_per_class=1000):\n",
        "    \"\"\"\n",
        "    Genera un dataset balanceado, con `samples_per_class` muestras por cada clase.\n",
        "    X: matriz (N, 4)\n",
        "    y: vector (N,)\n",
        "    \"\"\"\n",
        "    X_list, y_list = [], []\n",
        "    class_counts = [0, 0, 0] # Initialize counts for classes 0, 1, 2\n",
        "\n",
        "    while any(c < samples_per_class for c in class_counts):\n",
        "        x, label = generar_muestra()\n",
        "        if class_counts[label] < samples_per_class:\n",
        "            X_list.append(x)\n",
        "            y_list.append(label)\n",
        "            class_counts[label] += 1\n",
        "\n",
        "    X = np.vstack(X_list)\n",
        "    y = np.array(y_list, dtype=int)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# ============================================\n",
        "# 3. Crear dataset y explorar distribución\n",
        "# ============================================\n",
        "\n",
        "X, y = generar_dataset(samples_per_class=1000) # Modified call to generate a balanced dataset\n",
        "print(\"Dimensiones de X:\", X.shape)   # (N, 4)\n",
        "print(\"Dimensiones de y:\", y.shape)   # (N,)\n",
        "\n",
        "print(\"\\nPrimeras 5 filas de X:\\n\", X[:5])\n",
        "print(\"\\nPrimeras 5 etiquetas de y:\\n\", y[:5])\n",
        "\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "print(\"Distribución de clases (0=Normal, 1=Advertencia, 2=Crítico):\")\n",
        "for cls, cnt in zip(unique, counts):\n",
        "    print(f\"  Clase {cls}: {cnt} muestras ({cnt/len(y)*100:.1f}%)\")\n",
        "\n",
        "# ============================================\n",
        "# 4. Separar en entrenamiento y prueba\n",
        "# ============================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=0, stratify=y\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, \" Test:\", X_test.shape)\n",
        "\n",
        "# ============================================\n",
        "# 5. Definir y entrenar la MLP\n",
        "#    Arquitectura ejemplo: 4 -> 16 -> 3 (Updated)\n",
        "# ============================================\n",
        "\n",
        "mlp = MLPClassifier(\n",
        "    hidden_layer_sizes=(32,),    # una capa oculta de 16 neuronas (Updated)\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    max_iter=5000,               # Incrementado el número de iteraciones (Updated)\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# ============================================\n",
        "# 6. Evaluación\n",
        "# ============================================\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "print(\"\\nAccuracy en prueba:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_test, y_pred, digits=3))\n",
        "\n",
        "print(\"Matriz de confusión:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# ============================================\n",
        "# 7. Extraer pesos del MLP para la Raspberry Pi\n",
        "#    coefs_[0]: (n_features, n_hidden) -> (4, 16)\n",
        "#    coefs_[1]: (n_hidden, n_outputs) -> (16, 3)\n",
        "# ============================================\n",
        "\n",
        "W1 = mlp.coefs_[0]       # (4, 16) - Updated shape\n",
        "b1 = mlp.intercepts_[0]  # (16,) - Updated shape\n",
        "W2 = mlp.coefs_[1]       # (16, 3) - Updated shape\n",
        "b2 = mlp.intercepts_[1]  # (3,)\n",
        "\n",
        "# Custom formatter for floats to ensure 5 decimal places and no suppression\n",
        "float_formatter = lambda x: \"%.5f\" % x\n",
        "\n",
        "print(\"\\n=== Pesos para implementar en la Raspberry Pi ===\")\n",
        "print(\"W1.shape:\", W1.shape)\n",
        "print(\"W1 = np.array(\")\n",
        "print(np.array2string(W1, separator=', ', formatter={'float_kind':float_formatter}))\n",
        "print(\")\")\n",
        "print(\"\\nb1.shape:\", b1.shape)\n",
        "print(\"b1 = np.array(\")\n",
        "print(np.array2string(b1, separator=', ', formatter={'float_kind':float_formatter}))\n",
        "print(\")\")\n",
        "\n",
        "print(\"\\nW2.shape:\", W2.shape)\n",
        "print(\"W2 = np.array(\")\n",
        "print(np.array2string(W2, separator=', ', formatter={'float_kind':float_formatter}))\n",
        "print(\")\")\n",
        "print(\"\\nb2.shape:\", b2.shape)\n",
        "print(\"b2 = np.array(\")\n",
        "print(np.array2string(b2, separator=', ', formatter={'float_kind':float_formatter}))\n",
        "print(\")\")\n"
      ]
    }
  ]
}